{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 3\n",
    "LAYER_SIZE = 10\n",
    "S_LAYER_SIZE = 15\n",
    "LATENT_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from the file\n",
    "\n",
    "saved = np.load(\"testing1.npy\", allow_pickle=True)\n",
    "\n",
    "# Make a trainging and testing batch\n",
    "train_data = torch.Tensor(saved[:int(len(saved)*0.5)])\n",
    "test_data = torch.Tensor(saved[int(len(saved)*0.5):])\n",
    "print(train_data.shape)\n",
    "INPUT_SIZE = len(test_data[0])\n",
    "INPUT_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.l1 = nn.Linear(INPUT_SIZE, LAYER_SIZE)\n",
    "        self.l2a = nn.Linear(LAYER_SIZE, LATENT_SIZE)\n",
    "        self.l2b = nn.Linear(LAYER_SIZE, LATENT_SIZE)\n",
    "        \n",
    "        # Decoder\n",
    "        self.l3 = nn.Linear(LATENT_SIZE, LAYER_SIZE)\n",
    "        self.l4 = nn.Linear(LAYER_SIZE, INPUT_SIZE)\n",
    "            \n",
    "    # Run some data through the encoder\n",
    "    def encode(self, x):\n",
    "        out = F.relu(self.l1(x))\n",
    "        # return the mu and the sigma\n",
    "        return self.l2a(out), self.l2b(out)\n",
    "    \n",
    "    # The reparameterization trick, taken from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "    def reparameterize(self, mu, sigma):\n",
    "        std = torch.exp(0.5*sigma)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def decode(self, x):\n",
    "        out = F.relu(self.l3(x))\n",
    "        return torch.sigmoid(self.l4(out)) # sigmoid vs tanh\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: check the shape of x to be sure we have the right input\n",
    "        mu, sigma = self.encode(x)\n",
    "        z = self.reparameterize(mu, sigma)\n",
    "        # The loss function needs the mu and the sigma so just return them here\n",
    "        return self.decode(z), mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "# Taken from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "def loss_function(recon_x, x, mu, sigma):\n",
    "#     x = \n",
    "#     y = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + sigma - mu.pow(2) - sigma.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(e_count, model, optimizer):\n",
    "    data = train_data\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i in range(0, len(data), BATCH_SIZE):\n",
    "        batch = data[i:i+BATCH_SIZE].to(device)\n",
    "        model.zero_grad()\n",
    "        recons, mu, sigma = model(batch)\n",
    "        loss = loss_function(recons, batch, mu, sigma)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch: {e_count}, Loss: {train_loss/len(data)}\")        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use CPU\n",
    "def test(e_count, model, optimizer):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for i in range(0, len(test_data), BATCH_SIZE):\n",
    "        batch = test_data[i:i+BATCH_SIZE].to(device)\n",
    "        recons, mu, sigma = model(batch)\n",
    "        loss = loss_function(recons, batch, mu, sigma)\n",
    "        test_loss += loss.item()\n",
    "    print(f\"TEST Epoch: {e_count}, Loss: {test_loss/len(test_data)}\") \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data[torch.randperm(train_data.size()[0])]\n",
    "test_data=test_data[torch.randperm(test_data.size()[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae1 = VAE().to(device)\n",
    "opt1 = optim.Adam(vae1.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 7.509440319824218\n",
      "Epoch: 1, Loss: 7.183370754394531\n",
      "Epoch: 2, Loss: 7.0088898828125\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    train(i, vae1, opt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make(\"InvertedPendulum-v2\")\n",
    "env.reset()\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0] \n",
    "action_low = env.action_space.low[0]\n",
    "action_high = env.action_space.high[0]\n",
    "state_low = -10.0\n",
    "state_high = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descale(x):\n",
    "    # State\n",
    "    ((x[:, 0].mul_(state_high-state_low)).add_(state_low)).to(device)\n",
    "    ((x[:, 1].mul_(state_high-state_low)).add_(state_low)).to(device)\n",
    "    ((x[:, 2].mul_(state_high-state_low)).add_(state_low)).to(device)\n",
    "    ((x[:, 3].mul_(state_high-state_low)).add_(state_low)).to(device)\n",
    "\n",
    "    # Action\n",
    "    ((x[:, 4].mul_(action_high-action_low)).add_(action_low)).to(device)\n",
    "    \n",
    "    # State\n",
    "    ((x[:, 5].mul_(state_high-state_low)).add_(state_low)).to(device)\n",
    "    ((x[:, 6].mul_(state_high-state_low)).add_(state_low)).to(device)\n",
    "    ((x[:, 7].mul_(state_high-state_low)).add_(state_low)).to(device)\n",
    "    ((x[:, 8].mul_(state_high-state_low)).add_(state_low)).to(device)\n",
    "    \n",
    "    # Reward\n",
    "    (x[:, 9].mul_(20.0)).to(device)\n",
    "    \n",
    "    # Done\n",
    "    (x[:, 10].round_()).to(device)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action\n",
      "tensor(0.6896, device='cuda:0')\n",
      "tensor(0.4890, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.1875, device='cuda:0')\n",
      "tensor(0.5019, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.6406, device='cuda:0')\n",
      "tensor(0.4993, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.7215, device='cuda:0')\n",
      "tensor(0.5094, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.6110, device='cuda:0')\n",
      "tensor(0.5057, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.3201, device='cuda:0')\n",
      "tensor(0.4967, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.0472, device='cuda:0')\n",
      "tensor(0.5109, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.7684, device='cuda:0')\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.4446, device='cuda:0')\n",
      "tensor(0.5087, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.8828, device='cuda:0')\n",
      "tensor(0.4969, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "print(\"Action\")\n",
    "for i in range(10):\n",
    "    sample = torch.FloatTensor(2, 11).uniform_(0, 1).to(\"cuda\")\n",
    "    print(sample[0][5])\n",
    "    x = vae1(sample)\n",
    "    print(x[0][0][5], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward\n",
      "tensor(0.0844, device='cuda:0')\n",
      "tensor(0.0875, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.1331, device='cuda:0')\n",
      "tensor(0.1024, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.0859, device='cuda:0')\n",
      "tensor(0.1442, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.0629, device='cuda:0')\n",
      "tensor(0.2584, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.1313, device='cuda:0')\n",
      "tensor(0.1967, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.1076, device='cuda:0')\n",
      "tensor(0.0734, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.1192, device='cuda:0')\n",
      "tensor(0.1632, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.0221, device='cuda:0')\n",
      "tensor(0.1424, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.0138, device='cuda:0')\n",
      "tensor(0.1750, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor(0.0169, device='cuda:0')\n",
      "tensor(0.1519, device='cuda:0', grad_fn=<SelectBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Reward\")\n",
    "for i in range(10):\n",
    "    sample = torch.FloatTensor(2, 11).uniform_(0, 0.15).to(\"cuda\")\n",
    "    print(sample[0][9])\n",
    "    x = vae1(sample)\n",
    "    print(x[0][0][9], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:       tensor([[0.3326, 0.0023, 0.2534, 0.9361, 0.7955, 0.7620, 0.2810, 0.3772, 0.0728, 0.2364, 0.4963]])\n",
      "Reconstruction: tensor([[0.4516, 0.5441, 0.4798, 0.5115, 0.5390, 0.4983, 0.5348, 0.4998, 0.4904, 0.1753, 0.3520]], grad_fn=<CopyBackwards>)\n",
      "Loss: 7.537787437438965\n",
      "\n",
      "\n",
      "Original:       tensor([[0.3061, 0.6161, 0.4320, 0.6255, 0.6189, 0.5128, 0.3723, 0.6714, 0.1396, 0.2378, 0.1113]])\n",
      "Reconstruction: tensor([[0.4987, 0.5101, 0.5079, 0.5022, 0.4979, 0.4932, 0.4817, 0.5064, 0.5077, 0.1217, 0.2193]], grad_fn=<CopyBackwards>)\n",
      "Loss: 7.22882080078125\n",
      "\n",
      "\n",
      "Original:       tensor([[0.6172, 0.6287, 0.7405, 0.3829, 0.9664, 0.0034, 0.9259, 0.0628, 0.0771, 0.8421, 0.8242]])\n",
      "Reconstruction: tensor([[0.5107, 0.5062, 0.4897, 0.4747, 0.5014, 0.5015, 0.5037, 0.4838, 0.4935, 0.1738, 0.3061]], grad_fn=<CopyBackwards>)\n",
      "Loss: 8.753585815429688\n",
      "\n",
      "\n",
      "Original:       tensor([[0.2213, 0.9644, 0.4720, 0.8401, 0.2147, 0.2597, 0.8559, 0.9579, 0.4764, 0.5699, 0.0090]])\n",
      "Reconstruction: tensor([[0.4931, 0.5175, 0.5219, 0.4933, 0.5007, 0.5144, 0.5293, 0.4915, 0.5022, 0.2819, 0.3306]], grad_fn=<CopyBackwards>)\n",
      "Loss: 7.4806318283081055\n",
      "\n",
      "\n",
      "Original:       tensor([[0.3257, 0.1583, 0.1316, 0.2509, 0.3212, 0.5082, 0.1305, 0.8695, 0.5291, 0.7489, 0.0742]])\n",
      "Reconstruction: tensor([[0.5043, 0.5093, 0.5144, 0.4810, 0.5057, 0.5097, 0.5214, 0.4823, 0.4894, 0.1788, 0.2248]], grad_fn=<CopyBackwards>)\n",
      "Loss: 8.011959075927734\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(linewidth=140)\n",
    "for i in range(5):\n",
    "    sample = torch.FloatTensor(1, 11).uniform_(0, 1).to(\"cuda\")\n",
    "    x, m, s = vae1(sample)\n",
    "    loss = loss_function(x, sample, m, s)\n",
    "    \n",
    "    x = x.to(\"cpu\")\n",
    "    sample = sample.to(\"cpu\")\n",
    "    \n",
    "    print(f\"Original:       {sample}\")\n",
    "    print(f\"Reconstruction: {x}\")\n",
    "    print(f\"Loss: {loss}\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5002, 0.5004, 0.5002, 0.5002, 0.7774, 0.5009, 0.4989, 0.5306, 0.4299,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5003, 0.4996, 0.5001, 0.5002, 0.3954, 0.5001, 0.5001, 0.4887, 0.5265,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5001, 0.5001, 0.5001, 0.5004, 0.3878, 0.5052, 0.4886, 0.5533, 0.3803,\n",
      "        0.0500, 1.0000])\n",
      "tensor([0.5005, 0.4999, 0.5004, 0.5000, 0.0215, 0.4994, 0.5024, 0.4479, 0.6221,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4995, 0.4996, 0.4997, 0.5004, 0.7333, 0.4996, 0.4993, 0.5187, 0.4552,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5002, 0.4997, 0.4996, 0.4995, 0.4629, 0.5041, 0.4906, 0.5511, 0.3823,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5001, 0.4996, 0.5003, 0.5002, 0.7037, 0.5024, 0.4944, 0.5590, 0.3668,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5002, 0.5004, 0.4999, 0.4997, 0.6960, 0.4978, 0.5059, 0.4744, 0.5571,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4998, 0.4999, 0.4999, 0.5004, 0.9147, 0.4978, 0.5043, 0.5153, 0.4636,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5004, 0.5003, 0.5003, 0.5000, 0.5127, 0.5045, 0.4921, 0.4892, 0.5199,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4995, 0.4996, 0.4995, 0.5000, 0.6497, 0.5017, 0.4944, 0.5346, 0.4185,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4998, 0.5001, 0.5000, 0.5001, 0.5240, 0.5038, 0.4918, 0.5649, 0.3631,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4999, 0.5004, 0.5004, 0.4997, 0.5256, 0.4998, 0.5006, 0.5014, 0.4982,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5001, 0.4995, 0.4998, 0.4996, 0.9419, 0.5064, 0.4846, 0.5977, 0.2725,\n",
      "        0.0500, 1.0000])\n",
      "tensor([0.5005, 0.5001, 0.4996, 0.4997, 0.3747, 0.4984, 0.5058, 0.4995, 0.5198,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5001, 0.5003, 0.4996, 0.5004, 0.6074, 0.4970, 0.5069, 0.4731, 0.5550,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5005, 0.5005, 0.5001, 0.5001, 0.2257, 0.4991, 0.5055, 0.4856, 0.5530,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5002, 0.4995, 0.5004, 0.5003, 0.0912, 0.4986, 0.5032, 0.4770, 0.5572,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4997, 0.4998, 0.4997, 0.5002, 0.6835, 0.4932, 0.5136, 0.4297, 0.6486,\n",
      "        0.0500, 1.0000])\n",
      "tensor([0.4997, 0.4997, 0.4999, 0.4996, 0.7429, 0.4970, 0.5063, 0.5463, 0.4111,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5002, 0.4999, 0.4996, 0.5005, 0.2401, 0.5036, 0.4916, 0.4733, 0.5493,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5003, 0.5000, 0.5005, 0.5003, 0.1072, 0.4994, 0.5020, 0.4573, 0.6006,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5003, 0.5004, 0.5005, 0.5003, 0.1772, 0.4757, 0.5040, 0.4445, 0.5466,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5000, 0.4999, 0.5000, 0.4999, 0.2278, 0.5008, 0.4981, 0.4913, 0.5227,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4997, 0.5000, 0.5004, 0.5000, 0.0538, 0.4946, 0.5119, 0.3919, 0.7472,\n",
      "        0.0500, 1.0000])\n",
      "tensor([0.4995, 0.5001, 0.4999, 0.4997, 0.8791, 0.5004, 0.4982, 0.5415, 0.4032,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5003, 0.4999, 0.4997, 0.5003, 0.6523, 0.4927, 0.5138, 0.4599, 0.5865,\n",
      "        0.0500, 1.0000])\n",
      "tensor([0.4997, 0.5001, 0.4997, 0.4998, 0.8928, 0.5013, 0.4963, 0.5556, 0.3712,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4999, 0.5004, 0.5002, 0.4997, 0.0829, 0.4993, 0.5019, 0.4596, 0.5955,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5000, 0.4996, 0.4995, 0.4999, 0.5120, 0.5000, 0.4995, 0.5009, 0.4964,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5000, 0.5003, 0.4996, 0.5003, 0.5368, 0.4956, 0.5104, 0.4467, 0.6208,\n",
      "        0.0500, 1.0000])\n",
      "tensor([0.5003, 0.4999, 0.4995, 0.5003, 0.2747, 0.5025, 0.4948, 0.4924, 0.5164,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5002, 0.5004, 0.5001, 0.5000, 0.5531, 0.5050, 0.4892, 0.5098, 0.4659,\n",
      "        0.0500, 1.0000])\n",
      "tensor([0.5001, 0.4995, 0.4999, 0.4999, 0.1509, 0.4983, 0.5036, 0.4456, 0.6245,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4997, 0.4997, 0.5004, 0.4998, 0.1341, 0.5053, 0.4888, 0.5122, 0.4844,\n",
      "        0.0500, 1.0000])\n",
      "tensor([0.4998, 0.5002, 0.4997, 0.5005, 0.8587, 0.4942, 0.5130, 0.4660, 0.5782,\n",
      "        0.0500, 1.0000])\n",
      "tensor([0.5001, 0.5004, 0.5001, 0.5000, 0.8049, 0.5038, 0.4911, 0.5308, 0.4132,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4999, 0.5003, 0.5005, 0.5002, 0.6108, 0.5002, 0.4998, 0.5126, 0.4723,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4995, 0.4995, 0.4995, 0.5000, 0.3711, 0.5036, 0.4896, 0.5451, 0.3948,\n",
      "        0.0500, 1.0000])\n",
      "tensor([0.4998, 0.5000, 0.4996, 0.4999, 0.6027, 0.4969, 0.5067, 0.4860, 0.5315,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5004, 0.4995, 0.4999, 0.4995, 0.8490, 0.5035, 0.4921, 0.5672, 0.3463,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5002, 0.5005, 0.4997, 0.5002, 0.8804, 0.5011, 0.4985, 0.5417, 0.4037,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4997, 0.5000, 0.4996, 0.5001, 0.3295, 0.5015, 0.4957, 0.4915, 0.5158,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5004, 0.4997, 0.5005, 0.4996, 0.8003, 0.5010, 0.4981, 0.5335, 0.4226,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4998, 0.4998, 0.5002, 0.5004, 0.6399, 0.5021, 0.4947, 0.5468, 0.3939,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5004, 0.5003, 0.4996, 0.4999, 0.9907, 0.5015, 0.4977, 0.5535, 0.3751,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4995, 0.4999, 0.5003, 0.5004, 0.3445, 0.5038, 0.4901, 0.5391, 0.4124,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5004, 0.4996, 0.5001, 0.4998, 0.5405, 0.5030, 0.4935, 0.5380, 0.4125,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5003, 0.5000, 0.4999, 0.5004, 0.8046, 0.4962, 0.5095, 0.4847, 0.5351,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4998, 0.4999, 0.5005, 0.4995, 0.3941, 0.4996, 0.5004, 0.4889, 0.5265,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5004, 0.4998, 0.4999, 0.4996, 0.0364, 0.4963, 0.5092, 0.3986, 0.7308,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5003, 0.4997, 0.5004, 0.4995, 0.7163, 0.5001, 0.5001, 0.5130, 0.4691,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5005, 0.4996, 0.4996, 0.5003, 0.2358, 0.5029, 0.4942, 0.5209, 0.4584,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5004, 0.4997, 0.5004, 0.5003, 0.9073, 0.5013, 0.4976, 0.5452, 0.3961,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4998, 0.4999, 0.4998, 0.5002, 0.8940, 0.5039, 0.4905, 0.5881, 0.2990,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4997, 0.4998, 0.5002, 0.4998, 0.9555, 0.5000, 0.4989, 0.5216, 0.4436,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4996, 0.5000, 0.4996, 0.5002, 0.6037, 0.5004, 0.4980, 0.5129, 0.4693,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4995, 0.5002, 0.5005, 0.4995, 0.6380, 0.5020, 0.4955, 0.5638, 0.3662,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4996, 0.4997, 0.4997, 0.4997, 0.5345, 0.5012, 0.4978, 0.5519, 0.4065,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5003, 0.4999, 0.5003, 0.4997, 0.8855, 0.5044, 0.4904, 0.5717, 0.3353,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4998, 0.4995, 0.5001, 0.4998, 0.6658, 0.5025, 0.4948, 0.5645, 0.3670,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4997, 0.5003, 0.4996, 0.4996, 0.7028, 0.5047, 0.4886, 0.5595, 0.3592,\n",
      "        0.0500, 1.0000])\n",
      "tensor([0.4996, 0.5001, 0.5001, 0.5004, 0.0817, 0.5031, 0.4923, 0.4986, 0.5050,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5004, 0.4997, 0.4995, 0.5001, 0.3346, 0.4970, 0.5075, 0.4321, 0.6533,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5005, 0.4996, 0.4997, 0.5004, 0.4791, 0.5021, 0.4958, 0.5210, 0.4511,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5000, 0.5000, 0.4997, 0.4997, 0.2523, 0.4995, 0.5012, 0.4725, 0.5630,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4997, 0.5002, 0.4995, 0.5001, 0.4870, 0.5026, 0.4932, 0.5407, 0.4074,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5002, 0.5004, 0.5004, 0.4996, 0.4555, 0.4969, 0.5090, 0.4758, 0.5671,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5003, 0.4999, 0.5000, 0.4999, 0.1086, 0.4962, 0.5092, 0.4048, 0.7171,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4997, 0.5001, 0.5004, 0.5002, 0.9064, 0.5016, 0.4960, 0.5630, 0.3561,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5000, 0.5002, 0.4997, 0.4999, 0.7471, 0.5056, 0.4874, 0.5862, 0.3036,\n",
      "        0.0500, 1.0000])\n",
      "tensor([0.4999, 0.5001, 0.5003, 0.4997, 0.4645, 0.5039, 0.4910, 0.5385, 0.4132,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4998, 0.5001, 0.5005, 0.4995, 0.5984, 0.5005, 0.4985, 0.4999, 0.4999,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4998, 0.4998, 0.5003, 0.4996, 0.2545, 0.4982, 0.5052, 0.5005, 0.5223,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4995, 0.5004, 0.5000, 0.5004, 0.4704, 0.4950, 0.5066, 0.4494, 0.5909,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5003, 0.5002, 0.4997, 0.5002, 0.0117, 0.4992, 0.5027, 0.4461, 0.6251,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5003, 0.4999, 0.5001, 0.4995, 0.2969, 0.4963, 0.5090, 0.4759, 0.5611,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4995, 0.4996, 0.4996, 0.5000, 0.1608, 0.4964, 0.5096, 0.4805, 0.5712,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5003, 0.5002, 0.5004, 0.5003, 0.6373, 0.4996, 0.5017, 0.5073, 0.4848,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5003, 0.4996, 0.4998, 0.4998, 0.1562, 0.5041, 0.4906, 0.5137, 0.4677,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5000, 0.5000, 0.4999, 0.4996, 0.0944, 0.5020, 0.4953, 0.4836, 0.5358,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5000, 0.4997, 0.5004, 0.5002, 0.6241, 0.5003, 0.4991, 0.5141, 0.4683,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4997, 0.5002, 0.5001, 0.5001, 0.1298, 0.5005, 0.4983, 0.4870, 0.5331,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5001, 0.5004, 0.5002, 0.4997, 0.0953, 0.4994, 0.5021, 0.4586, 0.5975,\n",
      "        0.0500, 0.0000])\n",
      "tensor([5.0004e-01, 5.0044e-01, 4.9985e-01, 5.0004e-01, 4.3488e-04, 4.9747e-01,\n",
      "        5.1221e-01, 4.2346e-01, 7.1229e-01, 5.0000e-02, 1.0000e+00])\n",
      "tensor([0.4999, 0.4999, 0.5001, 0.5000, 0.0444, 0.4944, 0.5125, 0.4182, 0.6892,\n",
      "        0.0500, 1.0000])\n",
      "tensor([0.4999, 0.4996, 0.4998, 0.4999, 0.5345, 0.5011, 0.4974, 0.5346, 0.4311,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5003, 0.5000, 0.5001, 0.5001, 0.3402, 0.4986, 0.5040, 0.4777, 0.5527,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5000, 0.4998, 0.5002, 0.4999, 0.9044, 0.4988, 0.5025, 0.5105, 0.4738,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4997, 0.5003, 0.4995, 0.4997, 0.7152, 0.4971, 0.5061, 0.4816, 0.5403,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4998, 0.4998, 0.5002, 0.5001, 0.0365, 0.5001, 0.4993, 0.4702, 0.5708,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5002, 0.4996, 0.5005, 0.5002, 0.9325, 0.4987, 0.5032, 0.5251, 0.4446,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4998, 0.5004, 0.5003, 0.5000, 0.1050, 0.4916, 0.5193, 0.3658, 0.8044,\n",
      "        0.0500, 1.0000])\n",
      "tensor([0.5002, 0.4995, 0.4996, 0.5003, 0.4402, 0.4993, 0.5014, 0.4914, 0.5168,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5005, 0.4996, 0.5003, 0.4995, 0.8283, 0.5000, 0.5010, 0.5407, 0.4123,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.5002, 0.4997, 0.5004, 0.4998, 0.4068, 0.5021, 0.4954, 0.5147, 0.4659,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4999, 0.4996, 0.4996, 0.5000, 0.6555, 0.4977, 0.5045, 0.4765, 0.5505,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4999, 0.5004, 0.5004, 0.4996, 0.4985, 0.4995, 0.5016, 0.5017, 0.4985,\n",
      "        0.0500, 0.0000])\n",
      "tensor([0.4999, 0.5000, 0.4999, 0.4996, 0.6913, 0.5021, 0.4929, 0.5352, 0.4050,\n",
      "        0.0500, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "for i in range(99):\n",
    "    print(test_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5037, 0.5006, 0.4984, 0.4855, 0.5062, 0.5058, 0.5164, 0.4833, 0.4912,\n",
       "         0.1900, 0.3372], device='cuda:0', grad_fn=<SigmoidBackward>),\n",
       " tensor([ 0.0075, -0.0646,  0.0115,  0.0794], device='cuda:0',\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([0.0351, 0.0227, 0.0375, 0.0389], device='cuda:0',\n",
       "        grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae1(test_data[0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
