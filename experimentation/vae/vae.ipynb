{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 50\n",
    "LAYER_SIZE = 30\n",
    "S_LAYER_SIZE = 15\n",
    "LATENT_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data from the file\n",
    "\n",
    "saved = np.load(\"testing2.npy\", allow_pickle=True)\n",
    "\n",
    "# Make a trainging and testing batch\n",
    "train_data = torch.Tensor(saved[:int(len(saved)*0.5)])\n",
    "test_data = torch.Tensor(saved[int(len(saved)*0.5):])\n",
    "print(train_data.shape)\n",
    "INPUT_SIZE = len(test_data[0])\n",
    "INPUT_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.l1 = nn.Linear(INPUT_SIZE, LAYER_SIZE)\n",
    "        self.ltest1 = nn.Linear(LAYER_SIZE, S_LAYER_SIZE)\n",
    "        self.l2a = nn.Linear(S_LAYER_SIZE, LATENT_SIZE)\n",
    "        self.l2b = nn.Linear(S_LAYER_SIZE, LATENT_SIZE)\n",
    "        \n",
    "        # Decoder\n",
    "        self.l3 = nn.Linear(LATENT_SIZE, S_LAYER_SIZE)\n",
    "        self.ltest2 = nn.Linear(S_LAYER_SIZE, LAYER_SIZE)\n",
    "        self.l4 = nn.Linear(LAYER_SIZE, INPUT_SIZE)\n",
    "            \n",
    "    # Run some data through the encoder\n",
    "    def encode(self, x):\n",
    "        out = F.relu(self.l1(x))\n",
    "        out = F.relu(self.ltest1(out))\n",
    "        # return the mu and the sigma\n",
    "        return self.l2a(out), self.l2b(out)\n",
    "    \n",
    "    # The reparameterization trick, taken from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "    def reparameterize(self, mu, sigma):\n",
    "        std = torch.exp(0.5*sigma)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def decode(self, x):\n",
    "        out = F.relu(self.l3(x))\n",
    "        out = F.relu(self.ltest2(out))\n",
    "        return torch.sigmoid(self.l4(out)) # sigmoid vs tanh\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: check the shape of x to be sure we have the right input\n",
    "        mu, sigma = self.encode(x)\n",
    "        z = self.reparameterize(mu, sigma)\n",
    "        # The loss function needs the mu and the sigma so just return them here\n",
    "        return self.decode(z), mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "# Taken from https://github.com/pytorch/examples/blob/master/vae/main.py\n",
    "def loss_function(recon_x, x, mu, sigma):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + sigma - mu.pow(2) - sigma.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(e_count, model, optimizer, name, data):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i in range(0, len(data), BATCH_SIZE):\n",
    "        batch = data[i:i+BATCH_SIZE].to(device)\n",
    "        model.zero_grad()\n",
    "        recons, mu, sigma = model(batch)\n",
    "        loss = loss_function(recons, batch, mu, sigma)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f\"Model: {name}, -- Epoch: {e_count}, Loss: {train_loss/len(data)}\")        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use CPU\n",
    "def test(e_count, model, optimizer):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for i in range(0, len(test_data), BATCH_SIZE):\n",
    "        batch = test_data[i:i+BATCH_SIZE].to(device)\n",
    "        recons, mu, sigma = model(batch)\n",
    "        loss = loss_function(recons, batch, mu, sigma)\n",
    "        test_loss += loss.item()\n",
    "    print(f\"TEST Epoch: {e_count}, Loss: {test_loss/len(test_data)}\") \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data, balanced, size):\n",
    "    res = []\n",
    "    for d in data:\n",
    "        if d[10] == int(balanced):\n",
    "            res.append(d)\n",
    "        if len(res) == size:\n",
    "            break\n",
    "    return torch.Tensor(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data[torch.randperm(train_data.size()[0])]\n",
    "\n",
    "\n",
    "balanced = torch.cat((get_data(saved[:int(len(saved)*0.5)], True, 5000), get_data(saved[:int(len(saved)*0.5)], False, 5000)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5003, 0.4994, 0.5108,  ..., 0.0500, 1.0000, 1.0000],\n",
       "        [0.4998, 0.4998, 0.5004,  ..., 0.0500, 1.0000, 1.0000],\n",
       "        [0.5003, 0.5005, 0.5002,  ..., 0.0500, 1.0000, 1.0000],\n",
       "        ...,\n",
       "        [0.5003, 0.5001, 0.5003,  ..., 0.0500, 0.0000, 0.0000],\n",
       "        [0.4997, 0.5004, 0.5003,  ..., 0.0500, 0.0000, 0.0000],\n",
       "        [0.4997, 0.5004, 0.5003,  ..., 0.0500, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced=balanced[torch.randperm(balanced.size()[0])]\n",
    "# SHUFFLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4997, 0.4999, 0.4996,  ..., 0.0500, 1.0000, 1.0000],\n",
       "        [0.5004, 0.4996, 0.4997,  ..., 0.0500, 1.0000, 1.0000],\n",
       "        [0.5001, 0.5005, 0.4995,  ..., 0.0500, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.5004, 0.4999, 0.4996,  ..., 0.0500, 1.0000, 1.0000],\n",
       "        [0.4999, 0.5004, 0.5002,  ..., 0.0500, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5002, 0.4999,  ..., 0.0500, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TWO DATA SETS, TWO MODELS\n",
    "train_data = train_data[:len(balanced)]\n",
    "\n",
    "vae1 = VAE().to(device)\n",
    "opt1 = optim.Adam(vae1.parameters(), lr=0.001)\n",
    "\n",
    "vae2 = VAE().to(device)\n",
    "opt2 = optim.Adam(vae2.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: UNBALANCED, -- Epoch: 0, Loss: 8.014720105743407\n",
      "Model: UNBALANCED, -- Epoch: 1, Loss: 7.429765886688233\n",
      "Model: UNBALANCED, -- Epoch: 2, Loss: 7.354164664459229\n",
      "Model: UNBALANCED, -- Epoch: 3, Loss: 7.339857394409179\n",
      "Model: UNBALANCED, -- Epoch: 4, Loss: 7.281273257446289\n",
      "Model: UNBALANCED, -- Epoch: 5, Loss: 7.192210766601563\n",
      "Model: UNBALANCED, -- Epoch: 6, Loss: 7.133889051055908\n",
      "Model: UNBALANCED, -- Epoch: 7, Loss: 7.097110566711426\n",
      "Model: UNBALANCED, -- Epoch: 8, Loss: 7.089943119812012\n",
      "Model: UNBALANCED, -- Epoch: 9, Loss: 7.0802763771057124\n",
      "Model: UNBALANCED, -- Epoch: 10, Loss: 7.072044285583496\n",
      "Model: UNBALANCED, -- Epoch: 11, Loss: 7.074810023498535\n",
      "Model: UNBALANCED, -- Epoch: 12, Loss: 7.064478143310547\n",
      "Model: UNBALANCED, -- Epoch: 13, Loss: 7.066982730865479\n",
      "Model: UNBALANCED, -- Epoch: 14, Loss: 7.0612791053771975\n",
      "Model: UNBALANCED, -- Epoch: 15, Loss: 7.065830574035645\n",
      "Model: UNBALANCED, -- Epoch: 16, Loss: 7.054909981536865\n",
      "Model: UNBALANCED, -- Epoch: 17, Loss: 7.067197116088868\n",
      "Model: UNBALANCED, -- Epoch: 18, Loss: 7.064977555847168\n",
      "Model: UNBALANCED, -- Epoch: 19, Loss: 7.05399893951416\n",
      "Model: UNBALANCED, -- Epoch: 20, Loss: 7.043438191223145\n",
      "Model: UNBALANCED, -- Epoch: 21, Loss: 7.062214610290527\n",
      "Model: UNBALANCED, -- Epoch: 22, Loss: 7.046347736358642\n",
      "Model: UNBALANCED, -- Epoch: 23, Loss: 7.058587184143066\n",
      "Model: UNBALANCED, -- Epoch: 24, Loss: 7.06479024887085\n",
      "Model: UNBALANCED, -- Epoch: 25, Loss: 7.0521746955871585\n",
      "Model: UNBALANCED, -- Epoch: 26, Loss: 7.054648831176758\n",
      "Model: UNBALANCED, -- Epoch: 27, Loss: 7.049096611022949\n",
      "Model: UNBALANCED, -- Epoch: 28, Loss: 7.060518611145019\n",
      "Model: UNBALANCED, -- Epoch: 29, Loss: 7.0559190574646\n",
      "Model: UNBALANCED, -- Epoch: 30, Loss: 7.056994106292724\n",
      "Model: UNBALANCED, -- Epoch: 31, Loss: 7.0504201194763185\n",
      "Model: UNBALANCED, -- Epoch: 32, Loss: 7.055745396423339\n",
      "Model: UNBALANCED, -- Epoch: 33, Loss: 7.057120363616943\n",
      "Model: UNBALANCED, -- Epoch: 34, Loss: 7.04535072479248\n",
      "Model: UNBALANCED, -- Epoch: 35, Loss: 7.048714588928223\n",
      "Model: UNBALANCED, -- Epoch: 36, Loss: 7.03008131942749\n",
      "Model: UNBALANCED, -- Epoch: 37, Loss: 7.047900758361816\n",
      "Model: UNBALANCED, -- Epoch: 38, Loss: 7.0522447639465335\n",
      "Model: UNBALANCED, -- Epoch: 39, Loss: 7.045796292877197\n",
      "Model: UNBALANCED, -- Epoch: 40, Loss: 7.04861654663086\n",
      "Model: UNBALANCED, -- Epoch: 41, Loss: 7.046068218994141\n",
      "Model: UNBALANCED, -- Epoch: 42, Loss: 7.054921412658691\n",
      "Model: UNBALANCED, -- Epoch: 43, Loss: 7.051120014190674\n",
      "Model: UNBALANCED, -- Epoch: 44, Loss: 7.0504827972412105\n",
      "Model: UNBALANCED, -- Epoch: 45, Loss: 7.062266121673584\n",
      "Model: UNBALANCED, -- Epoch: 46, Loss: 7.044003982543945\n",
      "Model: UNBALANCED, -- Epoch: 47, Loss: 7.054980411529541\n",
      "Model: UNBALANCED, -- Epoch: 48, Loss: 7.045533442687988\n",
      "Model: UNBALANCED, -- Epoch: 49, Loss: 7.0539258850097655\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    train(i, vae1,opt1, \"UNBALANCED\" ,train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: BALANCED, -- Epoch: 0, Loss: 8.143030563354491\n",
      "Model: BALANCED, -- Epoch: 1, Loss: 7.855812112426758\n",
      "Model: BALANCED, -- Epoch: 2, Loss: 7.8358983757019045\n",
      "Model: BALANCED, -- Epoch: 3, Loss: 7.833433131408691\n",
      "Model: BALANCED, -- Epoch: 4, Loss: 7.830728870391845\n",
      "Model: BALANCED, -- Epoch: 5, Loss: 7.829301285552979\n",
      "Model: BALANCED, -- Epoch: 6, Loss: 7.826940181732177\n",
      "Model: BALANCED, -- Epoch: 7, Loss: 7.823282636260986\n",
      "Model: BALANCED, -- Epoch: 8, Loss: 7.801197055053711\n",
      "Model: BALANCED, -- Epoch: 9, Loss: 7.633588835144043\n",
      "Model: BALANCED, -- Epoch: 10, Loss: 7.489979894256591\n",
      "Model: BALANCED, -- Epoch: 11, Loss: 7.362941201019287\n",
      "Model: BALANCED, -- Epoch: 12, Loss: 7.372356440734864\n",
      "Model: BALANCED, -- Epoch: 13, Loss: 7.356009777069092\n",
      "Model: BALANCED, -- Epoch: 14, Loss: 7.345808758544922\n",
      "Model: BALANCED, -- Epoch: 15, Loss: 7.338908129882813\n",
      "Model: BALANCED, -- Epoch: 16, Loss: 7.355478516387939\n",
      "Model: BALANCED, -- Epoch: 17, Loss: 7.348306488800048\n",
      "Model: BALANCED, -- Epoch: 18, Loss: 7.348565782165528\n",
      "Model: BALANCED, -- Epoch: 19, Loss: 7.350906279754638\n",
      "Model: BALANCED, -- Epoch: 20, Loss: 7.343850115203858\n",
      "Model: BALANCED, -- Epoch: 21, Loss: 7.358262583160401\n",
      "Model: BALANCED, -- Epoch: 22, Loss: 7.3431323043823244\n",
      "Model: BALANCED, -- Epoch: 23, Loss: 7.345184712982178\n",
      "Model: BALANCED, -- Epoch: 24, Loss: 7.335938641357422\n",
      "Model: BALANCED, -- Epoch: 25, Loss: 7.3547720565795895\n",
      "Model: BALANCED, -- Epoch: 26, Loss: 7.34905445098877\n",
      "Model: BALANCED, -- Epoch: 27, Loss: 7.353141828155517\n",
      "Model: BALANCED, -- Epoch: 28, Loss: 7.346337207794189\n",
      "Model: BALANCED, -- Epoch: 29, Loss: 7.367466725158692\n",
      "Model: BALANCED, -- Epoch: 30, Loss: 7.345761298370362\n",
      "Model: BALANCED, -- Epoch: 31, Loss: 7.342381900024414\n",
      "Model: BALANCED, -- Epoch: 32, Loss: 7.352323607635498\n",
      "Model: BALANCED, -- Epoch: 33, Loss: 7.3531681640625\n",
      "Model: BALANCED, -- Epoch: 34, Loss: 7.348295825195312\n",
      "Model: BALANCED, -- Epoch: 35, Loss: 7.357753665924072\n",
      "Model: BALANCED, -- Epoch: 36, Loss: 7.335193938446045\n",
      "Model: BALANCED, -- Epoch: 37, Loss: 7.3504030288696285\n",
      "Model: BALANCED, -- Epoch: 38, Loss: 7.340394071960449\n",
      "Model: BALANCED, -- Epoch: 39, Loss: 7.349868484497071\n",
      "Model: BALANCED, -- Epoch: 40, Loss: 7.354601821136475\n",
      "Model: BALANCED, -- Epoch: 41, Loss: 7.335865631866455\n",
      "Model: BALANCED, -- Epoch: 42, Loss: 7.3389231475830075\n",
      "Model: BALANCED, -- Epoch: 43, Loss: 7.342823414611816\n",
      "Model: BALANCED, -- Epoch: 44, Loss: 7.332565490722656\n",
      "Model: BALANCED, -- Epoch: 45, Loss: 7.348782504272461\n",
      "Model: BALANCED, -- Epoch: 46, Loss: 7.3419879585266115\n",
      "Model: BALANCED, -- Epoch: 47, Loss: 7.328256916046143\n",
      "Model: BALANCED, -- Epoch: 48, Loss: 7.345099550628662\n",
      "Model: BALANCED, -- Epoch: 49, Loss: 7.344381617736817\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    train(i, vae2,opt2, \"BALANCED\" ,balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle test data\n",
    "test_data=test_data[torch.randperm(test_data.size()[0])]\n",
    "\n",
    "ex_done = None\n",
    "ex_notdone = None\n",
    "for a in test_data:\n",
    "    if a[10] == 1:\n",
    "        ex_done = a\n",
    "        break\n",
    "\n",
    "for a in test_data:\n",
    "    if a[10] == 0:\n",
    "        ex_notdone = a\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_done[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9956, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vae1(ex_done.to(\"cuda\")))[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9820, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vae2(ex_done.to(\"cuda\")))[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_notdone[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0008, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vae1(ex_notdone.to(\"cuda\")))[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0003, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vae2(ex_notdone.to(\"cuda\")))[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for d in balanced:\n",
    "    if d[10] == 1:\n",
    "        count += 1\n",
    "print((count/len(train_data))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.380000000000003\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for d in train_data:\n",
    "    if d[10] == 1:\n",
    "        count += 1\n",
    "print((count/len(train_data))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9997, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vae2(ex_done.to(\"cuda\")))[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0028, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vae2(ex_notdone.to(\"cuda\")))[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Variable(torch.randn(2, LATENT_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = vae2.decode(sample.to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.9980e-01, 5.0015e-01, 4.9799e-01, 5.0144e-01, 4.8283e-01, 5.0128e-01,\n",
       "         4.9824e-01, 4.9503e-01, 5.0696e-01, 5.0032e-02, 1.4295e-04, 1.5450e-04],\n",
       "        [4.9812e-01, 4.9982e-01, 4.9954e-01, 5.0108e-01, 4.8845e-01, 5.0018e-01,\n",
       "         4.9950e-01, 4.9500e-01, 4.9860e-01, 5.5382e-02, 3.0825e-01, 3.1554e-01]],\n",
       "       device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNBALANCED DATASET\n",
      "counts of intervals: [0, 0.1]: 7933, [0.1, 0.7]: 534, [0.7, 1]: 1533\n",
      "-- so the ratio to done and not done (deleting the middle ones) is 0.16194802450876822\n",
      "The real ration is 0.17494\n"
     ]
    }
   ],
   "source": [
    "res = [0, 0, 0]\n",
    "k = []\n",
    "for i in range(10000):\n",
    "    sample = Variable(torch.randn(1, LATENT_SIZE))\n",
    "    a = vae1.decode(sample.to(\"cuda\"))[0]\n",
    "    num = float(sum(list(a[10:])))\n",
    "    k.append(num)\n",
    "    if num < 0.2:\n",
    "        res[0] += 1\n",
    "    elif num <0.7:\n",
    "        res[1] += 1\n",
    "    else:\n",
    "        res[2] += 1\n",
    "        \n",
    "d = 0\n",
    "nd = 0\n",
    "\n",
    "for a in test_data:\n",
    "    if a[10] == 1:\n",
    "        d += 1\n",
    "    else:\n",
    "        nd += 1\n",
    "        \n",
    "        \n",
    "print(f\"UNBALANCED DATASET\")\n",
    "print(f\"counts of intervals: [0, 0.1]: {res[0]}, [0.1, 0.7]: {res[1]}, [0.7, 1]: {res[2]}\")\n",
    "print(f\"-- so the ratio to done and not done (deleting the middle ones) is {res[2]/(res[2]+res[0])}\")\n",
    "print(f\"The real ration is {d/(nd+d)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make(\"InvertedPendulum-v2\")\n",
    "env.reset()\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0] \n",
    "action_low = env.action_space.low[0]\n",
    "action_high = env.action_space.high[0]\n",
    "state_low = -10.0\n",
    "state_high = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descale(x):\n",
    "    # State\n",
    "    ((x[:, 0].mul_(state_high-state_low)).add_(state_low)).to(device)\n",
    "    ((x[:, 1].mul_(state_high-state_low)).add_(state_low)).to(device)\n",
    "    ((x[:, 2].mul_(state_high-state_low)).add_(state_low)).to(device)\n",
    "    ((x[:, 3].mul_(state_high-state_low)).add_(state_low)).to(device)\n",
    "\n",
    "    # Action\n",
    "    ((x[:, 4].mul_(action_high-action_low)).add_(action_low)).to(device)\n",
    "    \n",
    "    # State\n",
    "    ((x[:, 5].mul_(state_high-state_low)).add_(state_low)).to(device)\n",
    "    ((x[:, 6].mul_(state_high-state_low)).add_(state_low)).to(device)\n",
    "    ((x[:, 7].mul_(state_high-state_low)).add_(state_low)).to(device)\n",
    "    ((x[:, 8].mul_(state_high-state_low)).add_(state_low)).to(device)\n",
    "    \n",
    "    # Reward\n",
    "    (x[:, 9].mul_(20.0)).to(device)\n",
    "    \n",
    "    # Done\n",
    "    (x[:, 10].round_()).to(device)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4425e-07, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = Variable(torch.randn(2, LATENT_SIZE)).cuda()\n",
    "x = vae1.decode(sample)\n",
    "x[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = descale(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
